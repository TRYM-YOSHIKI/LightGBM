{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "# optuna経由でLightGBMをインポート\n",
    "import optuna.integration.lightgbm as lgb_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0          0          0          6          1          0          0   \n",
       "1   1          0          0          0          0          0          0   \n",
       "2   2          0          0          0          0          0          1   \n",
       "3   3          0          0          7          0          1          5   \n",
       "4   4          1          0          0          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_66  feature_67  feature_68  \\\n",
       "0          0          0          7  ...           0           0           0   \n",
       "1          0          0          0  ...           2           0           0   \n",
       "2          0          3          0  ...           0           0           0   \n",
       "3          2          2          0  ...           0           4           0   \n",
       "4          0          0          0  ...           0           0           0   \n",
       "\n",
       "   feature_69  feature_70  feature_71  feature_72  feature_73  feature_74  \\\n",
       "0           0           0           0           2           0           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           2           2           0           4           3           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "    target  \n",
       "0  Class_6  \n",
       "1  Class_6  \n",
       "2  Class_2  \n",
       "3  Class_8  \n",
       "4  Class_2  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csvファイルからPandas DataFrameへ読み込み\n",
    "train = pd.read_csv('train.csv', delimiter=',', low_memory=False)\n",
    "\n",
    "# 冒頭を表示して確認\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "feature_0        int64\n",
       "feature_1        int64\n",
       "feature_2        int64\n",
       "feature_3        int64\n",
       "                ...   \n",
       "feature_71       int64\n",
       "feature_72       int64\n",
       "feature_73       int64\n",
       "feature_74       int64\n",
       "target        category\n",
       "Length: 77, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainのtargetをカテゴリーに変換\n",
    "train.target = train.target.astype('category')\n",
    "\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    1\n",
       "3    7\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベルエンコーディング（LabelEncoder）\n",
    "le = LabelEncoder()\n",
    "encoded = le.fit_transform(train.target.values)\n",
    "decoded = le.inverse_transform(encoded)\n",
    "train.target = encoded\n",
    "\n",
    "# 冒頭を表示して確認\n",
    "train.target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 77), (40000, 77))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データとテストデータに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(train, test_size=0.2, random_state = 0)\n",
    "\n",
    "# 表示して確認\n",
    "(train_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 75), (160000,), (40000, 75), (40000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データとラベルを分割する\n",
    "X_train, y_train = train_set.drop(['target'], axis=1).drop(['id'], axis=1).values, train_set.target.values\n",
    "\n",
    "# 評価データとラベルを分割する\n",
    "X_test, y_test = test_set.drop(['target'], axis=1).drop(['id'], axis=1).values, test_set.target.values\n",
    "\n",
    "# 表示して確認\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをセット\n",
    "# 訓練データ\n",
    "lgb_train = lgb_o.Dataset(X_train, y_train)\n",
    "# 評価データ\n",
    "lgb_eval = lgb_o.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-30 00:09:48,038]\u001b[0m A new study created in memory with name: no-name-f35b93c2-5954-454f-9c2b-e96ec8402c09\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.638325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.636475:  14%|#4        | 1/7 [00:12<01:17, 12.84s/it]\u001b[32m[I 2021-06-30 00:10:00,901]\u001b[0m Trial 0 finished with value: 0.636475 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.636475.\u001b[0m\n",
      "feature_fraction, val_score: 0.636475:  14%|#4        | 1/7 [00:12<01:17, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_error: 0.636475\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.635950:  29%|##8       | 2/7 [00:27<01:06, 13.32s/it]\u001b[32m[I 2021-06-30 00:10:15,347]\u001b[0m Trial 1 finished with value: 0.63595 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.63595.\u001b[0m\n",
      "feature_fraction, val_score: 0.635950:  29%|##8       | 2/7 [00:27<01:06, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_error: 0.63595\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.635950:  43%|####2     | 3/7 [00:54<01:10, 17.60s/it]\u001b[32m[I 2021-06-30 00:10:42,947]\u001b[0m Trial 2 finished with value: 0.6362 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.63595.\u001b[0m\n",
      "feature_fraction, val_score: 0.635950:  43%|####2     | 3/7 [00:54<01:10, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's multi_error: 0.6362\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.635075:  57%|#####7    | 4/7 [01:31<01:10, 23.34s/it]\u001b[32m[I 2021-06-30 00:11:19,661]\u001b[0m Trial 3 finished with value: 0.635075 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.635075.\u001b[0m\n",
      "feature_fraction, val_score: 0.635075:  57%|#####7    | 4/7 [01:31<01:10, 23.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_error: 0.635075\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.637075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.635075:  71%|#######1  | 5/7 [01:55<00:47, 23.54s/it]\u001b[32m[I 2021-06-30 00:11:43,669]\u001b[0m Trial 4 finished with value: 0.6363 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.635075.\u001b[0m\n",
      "feature_fraction, val_score: 0.635075:  71%|#######1  | 5/7 [01:55<00:47, 23.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_error: 0.6363\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.634825:  86%|########5 | 6/7 [02:28<00:26, 26.49s/it]\u001b[32m[I 2021-06-30 00:12:17,050]\u001b[0m Trial 5 finished with value: 0.634825 and parameters: {'feature_fraction': 0.5}. Best is trial 5 with value: 0.634825.\u001b[0m\n",
      "feature_fraction, val_score: 0.634825:  86%|########5 | 6/7 [02:28<00:26, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_error: 0.634825\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.634775: 100%|##########| 7/7 [02:42<00:00, 22.63s/it]\u001b[32m[I 2021-06-30 00:12:30,665]\u001b[0m Trial 6 finished with value: 0.634775 and parameters: {'feature_fraction': 0.7}. Best is trial 6 with value: 0.634775.\u001b[0m\n",
      "feature_fraction, val_score: 0.634775: 100%|##########| 7/7 [02:42<00:00, 23.23s/it]\n",
      "num_leaves, val_score: 0.634775:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_error: 0.634775\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.644875\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_error: 0.637125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.634775:   5%|5         | 1/20 [00:23<07:33, 23.86s/it]\u001b[32m[I 2021-06-30 00:12:54,540]\u001b[0m Trial 7 finished with value: 0.637125 and parameters: {'num_leaves': 205}. Best is trial 7 with value: 0.637125.\u001b[0m\n",
      "num_leaves, val_score: 0.634775:   5%|5         | 1/20 [00:23<07:33, 23.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.634775:  10%|#         | 2/20 [00:37<06:15, 20.86s/it]\u001b[32m[I 2021-06-30 00:13:08,410]\u001b[0m Trial 8 finished with value: 0.635225 and parameters: {'num_leaves': 32}. Best is trial 8 with value: 0.635225.\u001b[0m\n",
      "num_leaves, val_score: 0.634775:  10%|#         | 2/20 [00:37<06:15, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's multi_error: 0.635225\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.64335\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_error: 0.63855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.634775:  15%|#5        | 3/20 [01:05<06:30, 22.97s/it]\u001b[32m[I 2021-06-30 00:13:36,313]\u001b[0m Trial 9 finished with value: 0.63855 and parameters: {'num_leaves': 186}. Best is trial 8 with value: 0.635225.\u001b[0m\n",
      "num_leaves, val_score: 0.634775:  15%|#5        | 3/20 [01:05<06:30, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.634775:  20%|##        | 4/20 [01:25<05:52, 22.04s/it]\u001b[32m[I 2021-06-30 00:13:56,192]\u001b[0m Trial 10 finished with value: 0.636025 and parameters: {'num_leaves': 22}. Best is trial 8 with value: 0.635225.\u001b[0m\n",
      "num_leaves, val_score: 0.634775:  20%|##        | 4/20 [01:25<05:52, 22.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_error: 0.636025\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.64225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.634775:  25%|##5       | 5/20 [01:47<05:30, 22.00s/it]\u001b[32m[I 2021-06-30 00:14:18,089]\u001b[0m Trial 11 finished with value: 0.638025 and parameters: {'num_leaves': 115}. Best is trial 8 with value: 0.635225.\u001b[0m\n",
      "num_leaves, val_score: 0.634775:  25%|##5       | 5/20 [01:47<05:30, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_error: 0.638025\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  30%|###       | 6/20 [02:01<04:33, 19.54s/it]\u001b[32m[I 2021-06-30 00:14:31,868]\u001b[0m Trial 12 finished with value: 0.633975 and parameters: {'num_leaves': 19}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  30%|###       | 6/20 [02:01<04:33, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.645\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_error: 0.638625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  35%|###5      | 7/20 [02:23<04:25, 20.39s/it]\u001b[32m[I 2021-06-30 00:14:54,243]\u001b[0m Trial 13 finished with value: 0.638625 and parameters: {'num_leaves': 229}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  35%|###5      | 7/20 [02:23<04:25, 20.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.64245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  40%|####      | 8/20 [02:50<04:27, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_error: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-30 00:15:20,927]\u001b[0m Trial 14 finished with value: 0.6379 and parameters: {'num_leaves': 161}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  40%|####      | 8/20 [02:50<04:27, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  45%|####5     | 9/20 [03:02<03:33, 19.37s/it]\u001b[32m[I 2021-06-30 00:15:33,504]\u001b[0m Trial 15 finished with value: 0.63475 and parameters: {'num_leaves': 20}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  45%|####5     | 9/20 [03:02<03:33, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_error: 0.63475\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.64735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  50%|#####     | 10/20 [03:26<03:25, 20.55s/it]\u001b[32m[I 2021-06-30 00:15:56,823]\u001b[0m Trial 16 finished with value: 0.6382 and parameters: {'num_leaves': 236}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  50%|#####     | 10/20 [03:26<03:25, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_error: 0.6382\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.640175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  55%|#####5    | 11/20 [03:42<02:53, 19.32s/it]\u001b[32m[I 2021-06-30 00:16:13,280]\u001b[0m Trial 17 finished with value: 0.636825 and parameters: {'num_leaves': 83}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  55%|#####5    | 11/20 [03:42<02:53, 19.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_error: 0.636825\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.639675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  60%|######    | 12/20 [03:56<02:22, 17.77s/it]\u001b[32m[I 2021-06-30 00:16:27,405]\u001b[0m Trial 18 finished with value: 0.636575 and parameters: {'num_leaves': 66}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  60%|######    | 12/20 [03:56<02:22, 17.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_error: 0.636575\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635875\n",
      "[200]\tvalid_0's multi_error: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  65%|######5   | 13/20 [04:07<01:48, 15.52s/it]\u001b[32m[I 2021-06-30 00:16:37,698]\u001b[0m Trial 19 finished with value: 0.634175 and parameters: {'num_leaves': 2}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  65%|######5   | 13/20 [04:07<01:48, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_error: 0.634175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6362\n",
      "[200]\tvalid_0's multi_error: 0.63575\n",
      "[300]\tvalid_0's multi_error: 0.635725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  70%|#######   | 14/20 [04:24<01:36, 16.14s/it]\u001b[32m[I 2021-06-30 00:16:55,275]\u001b[0m Trial 20 finished with value: 0.634875 and parameters: {'num_leaves': 3}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  70%|#######   | 14/20 [04:24<01:36, 16.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_error: 0.634875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  75%|#######5  | 15/20 [04:39<01:19, 15.90s/it]\u001b[32m[I 2021-06-30 00:17:10,600]\u001b[0m Trial 21 finished with value: 0.6352 and parameters: {'num_leaves': 57}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  75%|#######5  | 15/20 [04:39<01:19, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_error: 0.6352\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.64035\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_error: 0.63665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  80%|########  | 16/20 [04:58<01:06, 16.73s/it]\u001b[32m[I 2021-06-30 00:17:29,278]\u001b[0m Trial 22 finished with value: 0.63665 and parameters: {'num_leaves': 101}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  80%|########  | 16/20 [04:58<01:06, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6362\n",
      "[200]\tvalid_0's multi_error: 0.63575\n",
      "[300]\tvalid_0's multi_error: 0.635725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  85%|########5 | 17/20 [05:16<00:51, 17.10s/it]\u001b[32m[I 2021-06-30 00:17:47,243]\u001b[0m Trial 23 finished with value: 0.634875 and parameters: {'num_leaves': 3}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  85%|########5 | 17/20 [05:16<00:51, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_error: 0.634875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.637175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  90%|######### | 18/20 [05:30<00:32, 16.15s/it]\u001b[32m[I 2021-06-30 00:18:01,186]\u001b[0m Trial 24 finished with value: 0.63555 and parameters: {'num_leaves': 44}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  90%|######### | 18/20 [05:30<00:32, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_error: 0.63555\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.644975\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_error: 0.638525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975:  95%|#########5| 19/20 [05:51<00:17, 17.64s/it]\u001b[32m[I 2021-06-30 00:18:22,301]\u001b[0m Trial 25 finished with value: 0.638525 and parameters: {'num_leaves': 149}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975:  95%|#########5| 19/20 [05:51<00:17, 17.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635875\n",
      "[200]\tvalid_0's multi_error: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.633975: 100%|##########| 20/20 [06:02<00:00, 15.58s/it]\u001b[32m[I 2021-06-30 00:18:33,069]\u001b[0m Trial 26 finished with value: 0.634175 and parameters: {'num_leaves': 2}. Best is trial 12 with value: 0.633975.\u001b[0m\n",
      "num_leaves, val_score: 0.633975: 100%|##########| 20/20 [06:02<00:00, 18.12s/it]\n",
      "bagging, val_score: 0.633975:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_error: 0.634175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  10%|#         | 1/10 [00:15<02:16, 15.12s/it]\u001b[32m[I 2021-06-30 00:18:48,205]\u001b[0m Trial 27 finished with value: 0.635975 and parameters: {'bagging_fraction': 0.9699812750727377, 'bagging_freq': 7}. Best is trial 27 with value: 0.635975.\u001b[0m\n",
      "bagging, val_score: 0.633975:  10%|#         | 1/10 [00:15<02:16, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_error: 0.635975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  20%|##        | 2/10 [00:29<01:59, 14.95s/it]\u001b[32m[I 2021-06-30 00:19:02,760]\u001b[0m Trial 28 finished with value: 0.63585 and parameters: {'bagging_fraction': 0.7286334134319907, 'bagging_freq': 1}. Best is trial 28 with value: 0.63585.\u001b[0m\n",
      "bagging, val_score: 0.633975:  20%|##        | 2/10 [00:29<01:59, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_error: 0.63585\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  30%|###       | 3/10 [00:42<01:39, 14.19s/it]\u001b[32m[I 2021-06-30 00:19:15,167]\u001b[0m Trial 29 finished with value: 0.6367 and parameters: {'bagging_fraction': 0.5452216407481592, 'bagging_freq': 3}. Best is trial 28 with value: 0.63585.\u001b[0m\n",
      "bagging, val_score: 0.633975:  30%|###       | 3/10 [00:42<01:39, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_error: 0.6367\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.637075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  40%|####      | 4/10 [00:55<01:24, 14.03s/it]\u001b[32m[I 2021-06-30 00:19:28,815]\u001b[0m Trial 30 finished with value: 0.636175 and parameters: {'bagging_fraction': 0.6449310260934901, 'bagging_freq': 4}. Best is trial 28 with value: 0.63585.\u001b[0m\n",
      "bagging, val_score: 0.633975:  40%|####      | 4/10 [00:55<01:24, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_error: 0.636175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63665\n",
      "[200]\tvalid_0's multi_error: 0.639175\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_error: 0.636425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  50%|#####     | 5/10 [01:13<01:15, 15.12s/it]\u001b[32m[I 2021-06-30 00:19:46,474]\u001b[0m Trial 31 finished with value: 0.636425 and parameters: {'bagging_fraction': 0.7396272996014521, 'bagging_freq': 7}. Best is trial 28 with value: 0.63585.\u001b[0m\n",
      "bagging, val_score: 0.633975:  50%|#####     | 5/10 [01:13<01:15, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  60%|######    | 6/10 [01:28<01:00, 15.06s/it]\u001b[32m[I 2021-06-30 00:20:01,388]\u001b[0m Trial 32 finished with value: 0.637775 and parameters: {'bagging_fraction': 0.40529948306809854, 'bagging_freq': 1}. Best is trial 28 with value: 0.63585.\u001b[0m\n",
      "bagging, val_score: 0.633975:  60%|######    | 6/10 [01:28<01:00, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_error: 0.637775\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  70%|#######   | 7/10 [01:45<00:47, 15.73s/it]\u001b[32m[I 2021-06-30 00:20:18,706]\u001b[0m Trial 33 finished with value: 0.634725 and parameters: {'bagging_fraction': 0.8941409087474881, 'bagging_freq': 7}. Best is trial 33 with value: 0.634725.\u001b[0m\n",
      "bagging, val_score: 0.633975:  70%|#######   | 7/10 [01:45<00:47, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_error: 0.634725\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  80%|########  | 8/10 [02:02<00:32, 16.20s/it]\u001b[32m[I 2021-06-30 00:20:35,990]\u001b[0m Trial 34 finished with value: 0.6349 and parameters: {'bagging_fraction': 0.9230948881476997, 'bagging_freq': 3}. Best is trial 33 with value: 0.634725.\u001b[0m\n",
      "bagging, val_score: 0.633975:  80%|########  | 8/10 [02:02<00:32, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_error: 0.6349\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.638225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975:  90%|######### | 9/10 [02:18<00:15, 15.98s/it]\u001b[32m[I 2021-06-30 00:20:51,458]\u001b[0m Trial 35 finished with value: 0.63605 and parameters: {'bagging_fraction': 0.6978055019986031, 'bagging_freq': 6}. Best is trial 33 with value: 0.634725.\u001b[0m\n",
      "bagging, val_score: 0.633975:  90%|######### | 9/10 [02:18<00:15, 15.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_error: 0.63605\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.639725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.633975: 100%|##########| 10/10 [02:31<00:00, 15.04s/it]\u001b[32m[I 2021-06-30 00:21:04,319]\u001b[0m Trial 36 finished with value: 0.6377 and parameters: {'bagging_fraction': 0.45439132886394173, 'bagging_freq': 7}. Best is trial 33 with value: 0.634725.\u001b[0m\n",
      "bagging, val_score: 0.633975: 100%|##########| 10/10 [02:31<00:00, 15.12s/it]\n",
      "feature_fraction_stage2, val_score: 0.633975:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_error: 0.6377\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.633975:  17%|#6        | 1/6 [00:16<01:22, 16.55s/it]\u001b[32m[I 2021-06-30 00:21:20,889]\u001b[0m Trial 37 finished with value: 0.63615 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.63615.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.633975:  17%|#6        | 1/6 [00:16<01:22, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_error: 0.63615\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.633975:  33%|###3      | 2/6 [00:32<01:04, 16.25s/it]\u001b[32m[I 2021-06-30 00:21:36,443]\u001b[0m Trial 38 finished with value: 0.635875 and parameters: {'feature_fraction': 0.652}. Best is trial 38 with value: 0.635875.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.633975:  33%|###3      | 2/6 [00:32<01:04, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's multi_error: 0.635875\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.633975:  50%|#####     | 3/6 [00:50<00:51, 17.02s/it]\u001b[32m[I 2021-06-30 00:21:55,273]\u001b[0m Trial 39 finished with value: 0.634525 and parameters: {'feature_fraction': 0.62}. Best is trial 39 with value: 0.634525.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.633975:  50%|#####     | 3/6 [00:50<00:51, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_error: 0.634525\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635875\n",
      "[200]\tvalid_0's multi_error: 0.63745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.633975:  67%|######6   | 4/6 [01:04<00:32, 16.06s/it]\u001b[32m[I 2021-06-30 00:22:09,073]\u001b[0m Trial 40 finished with value: 0.6352 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 39 with value: 0.634525.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.633975:  67%|######6   | 4/6 [01:04<00:32, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_error: 0.6352\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.634925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.633975:  83%|########3 | 5/6 [01:17<00:14, 14.99s/it]\u001b[32m[I 2021-06-30 00:22:21,572]\u001b[0m Trial 41 finished with value: 0.63415 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 41 with value: 0.63415.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.633975:  83%|########3 | 5/6 [01:17<00:14, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_error: 0.63415\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.633975: 100%|##########| 6/6 [01:31<00:00, 14.81s/it]\u001b[32m[I 2021-06-30 00:22:35,961]\u001b[0m Trial 42 finished with value: 0.6346 and parameters: {'feature_fraction': 0.716}. Best is trial 41 with value: 0.63415.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.633975: 100%|##########| 6/6 [01:31<00:00, 15.27s/it]\n",
      "regularization_factors, val_score: 0.633975:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_error: 0.6346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:   5%|5         | 1/20 [00:16<05:07, 16.19s/it]\u001b[32m[I 2021-06-30 00:22:52,163]\u001b[0m Trial 43 finished with value: 0.635475 and parameters: {'lambda_l1': 2.200727780899263e-05, 'lambda_l2': 0.5194656353014179}. Best is trial 43 with value: 0.635475.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:   5%|5         | 1/20 [00:16<05:07, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_error: 0.635475\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  10%|#         | 2/20 [00:29<04:38, 15.46s/it]\u001b[32m[I 2021-06-30 00:23:05,923]\u001b[0m Trial 44 finished with value: 0.633975 and parameters: {'lambda_l1': 1.4777805050741642e-07, 'lambda_l2': 1.069139832806073e-08}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  10%|#         | 2/20 [00:29<04:38, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  15%|#5        | 3/20 [00:46<04:28, 15.80s/it]\u001b[32m[I 2021-06-30 00:23:22,527]\u001b[0m Trial 45 finished with value: 0.63495 and parameters: {'lambda_l1': 1.5159989752582712, 'lambda_l2': 0.00042375529460374813}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  15%|#5        | 3/20 [00:46<04:28, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_error: 0.63495\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63595\n",
      "[200]\tvalid_0's multi_error: 0.638125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  20%|##        | 4/20 [01:04<04:23, 16.50s/it]\u001b[32m[I 2021-06-30 00:23:40,647]\u001b[0m Trial 46 finished with value: 0.635875 and parameters: {'lambda_l1': 0.11513264675707735, 'lambda_l2': 0.0023517787625033024}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  20%|##        | 4/20 [01:04<04:23, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_error: 0.635875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  25%|##5       | 5/20 [01:21<04:08, 16.57s/it]\u001b[32m[I 2021-06-30 00:23:57,376]\u001b[0m Trial 47 finished with value: 0.634925 and parameters: {'lambda_l1': 0.5659829571600496, 'lambda_l2': 7.933585999145839}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  25%|##5       | 5/20 [01:21<04:08, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_error: 0.634925\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  30%|###       | 6/20 [01:47<04:31, 19.39s/it]\u001b[32m[I 2021-06-30 00:24:23,341]\u001b[0m Trial 48 finished with value: 0.633975 and parameters: {'lambda_l1': 1.3479676497356033e-06, 'lambda_l2': 4.933195728557726e-07}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  30%|###       | 6/20 [01:47<04:31, 19.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  35%|###5      | 7/20 [02:00<03:49, 17.62s/it]\u001b[32m[I 2021-06-30 00:24:36,835]\u001b[0m Trial 49 finished with value: 0.633975 and parameters: {'lambda_l1': 9.627187674023124e-05, 'lambda_l2': 0.4723108185862983}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  35%|###5      | 7/20 [02:00<03:49, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  40%|####      | 8/20 [02:14<03:18, 16.53s/it]\u001b[32m[I 2021-06-30 00:24:50,835]\u001b[0m Trial 50 finished with value: 0.634575 and parameters: {'lambda_l1': 0.005769878132021392, 'lambda_l2': 1.7230064744112648e-06}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  40%|####      | 8/20 [02:14<03:18, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_error: 0.634575\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.636775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  45%|####5     | 9/20 [02:29<02:54, 15.85s/it]\u001b[32m[I 2021-06-30 00:25:05,086]\u001b[0m Trial 51 finished with value: 0.6353 and parameters: {'lambda_l1': 0.0028491274516079627, 'lambda_l2': 3.1101941092978434e-05}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  45%|####5     | 9/20 [02:29<02:54, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_error: 0.6353\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  50%|#####     | 10/20 [02:41<02:29, 14.93s/it]\u001b[32m[I 2021-06-30 00:25:17,857]\u001b[0m Trial 52 finished with value: 0.6346 and parameters: {'lambda_l1': 0.483834261251929, 'lambda_l2': 2.0927330805963532e-05}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  50%|#####     | 10/20 [02:41<02:29, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_error: 0.6346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  55%|#####5    | 11/20 [02:56<02:13, 14.82s/it]\u001b[32m[I 2021-06-30 00:25:32,420]\u001b[0m Trial 53 finished with value: 0.633975 and parameters: {'lambda_l1': 1.9556775606108463e-08, 'lambda_l2': 2.2059792236696343e-08}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  55%|#####5    | 11/20 [02:56<02:13, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  60%|######    | 12/20 [03:14<02:07, 15.88s/it]\u001b[32m[I 2021-06-30 00:25:50,796]\u001b[0m Trial 54 finished with value: 0.633975 and parameters: {'lambda_l1': 1.638475036907605e-07, 'lambda_l2': 2.597584345894281e-08}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  60%|######    | 12/20 [03:14<02:07, 15.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  65%|######5   | 13/20 [03:28<01:47, 15.32s/it]\u001b[32m[I 2021-06-30 00:26:04,812]\u001b[0m Trial 55 finished with value: 0.633975 and parameters: {'lambda_l1': 8.954776480946923e-07, 'lambda_l2': 3.7215077493264554e-07}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  65%|######5   | 13/20 [03:28<01:47, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  70%|#######   | 14/20 [03:42<01:29, 14.85s/it]\u001b[32m[I 2021-06-30 00:26:18,552]\u001b[0m Trial 56 finished with value: 0.633975 and parameters: {'lambda_l1': 2.6675692360367713e-06, 'lambda_l2': 2.3308411220255027e-08}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  70%|#######   | 14/20 [03:42<01:29, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  75%|#######5  | 15/20 [03:56<01:13, 14.65s/it]\u001b[32m[I 2021-06-30 00:26:32,733]\u001b[0m Trial 57 finished with value: 0.633975 and parameters: {'lambda_l1': 2.1084320888817302e-08, 'lambda_l2': 5.984799941673662e-07}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  75%|#######5  | 15/20 [03:56<01:13, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  80%|########  | 16/20 [04:10<00:56, 14.24s/it]\u001b[32m[I 2021-06-30 00:26:46,030]\u001b[0m Trial 58 finished with value: 0.633975 and parameters: {'lambda_l1': 5.544030580540719e-06, 'lambda_l2': 1.2941175435709873e-08}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  80%|########  | 16/20 [04:10<00:56, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  85%|########5 | 17/20 [04:23<00:41, 13.95s/it]\u001b[32m[I 2021-06-30 00:26:59,306]\u001b[0m Trial 59 finished with value: 0.633975 and parameters: {'lambda_l1': 1.379807701084494e-07, 'lambda_l2': 2.2643380278631868e-07}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  85%|########5 | 17/20 [04:23<00:41, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  90%|######### | 18/20 [04:36<00:27, 13.82s/it]\u001b[32m[I 2021-06-30 00:27:12,811]\u001b[0m Trial 60 finished with value: 0.633975 and parameters: {'lambda_l1': 1.1567211678647001e-07, 'lambda_l2': 9.225840637944367e-06}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  90%|######### | 18/20 [04:36<00:27, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975:  95%|#########5| 19/20 [04:49<00:13, 13.33s/it]\u001b[32m[I 2021-06-30 00:27:25,010]\u001b[0m Trial 61 finished with value: 0.635075 and parameters: {'lambda_l1': 1.5293425980076164e-08, 'lambda_l2': 0.002500883332790761}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975:  95%|#########5| 19/20 [04:49<00:13, 13.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_error: 0.635075\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.633975: 100%|##########| 20/20 [05:02<00:00, 13.31s/it]\u001b[32m[I 2021-06-30 00:27:38,283]\u001b[0m Trial 62 finished with value: 0.633975 and parameters: {'lambda_l1': 1.840280065821245e-07, 'lambda_l2': 1.4556512924300431e-07}. Best is trial 44 with value: 0.633975.\u001b[0m\n",
      "regularization_factors, val_score: 0.633975: 100%|##########| 20/20 [05:02<00:00, 15.12s/it]\n",
      "min_data_in_leaf, val_score: 0.633975:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_error: 0.633975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.63605\n",
      "[200]\tvalid_0's multi_error: 0.636175\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_error: 0.6355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.633975:  20%|##        | 1/5 [00:14<00:57, 14.30s/it]\u001b[32m[I 2021-06-30 00:27:52,591]\u001b[0m Trial 63 finished with value: 0.6355 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.6355.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.633975:  20%|##        | 1/5 [00:14<00:57, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.633975:  40%|####      | 2/5 [00:26<00:40, 13.57s/it]\u001b[32m[I 2021-06-30 00:28:04,469]\u001b[0m Trial 64 finished with value: 0.634925 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.634925.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.633975:  40%|####      | 2/5 [00:26<00:40, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_error: 0.634925\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635725\n",
      "[200]\tvalid_0's multi_error: 0.638275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.633975:  60%|######    | 3/5 [00:40<00:27, 13.69s/it]\u001b[32m[I 2021-06-30 00:28:18,427]\u001b[0m Trial 65 finished with value: 0.6356 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.634925.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.633975:  60%|######    | 3/5 [00:40<00:27, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_error: 0.6356\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.635625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.633975:  80%|########  | 4/5 [00:51<00:13, 13.03s/it]\u001b[32m[I 2021-06-30 00:28:29,932]\u001b[0m Trial 66 finished with value: 0.634675 and parameters: {'min_child_samples': 25}. Best is trial 66 with value: 0.634675.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.633975:  80%|########  | 4/5 [00:51<00:13, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_error: 0.634675\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3288\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -3.086615\n",
      "[LightGBM] [Info] Start training from score -2.096791\n",
      "[LightGBM] [Info] Start training from score -2.601750\n",
      "[LightGBM] [Info] Start training from score -3.752885\n",
      "[LightGBM] [Info] Start training from score -4.183176\n",
      "[LightGBM] [Info] Start training from score -1.351507\n",
      "[LightGBM] [Info] Start training from score -2.606566\n",
      "[LightGBM] [Info] Start training from score -1.353174\n",
      "[LightGBM] [Info] Start training from score -2.058904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_error: 0.6359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.633975: 100%|##########| 5/5 [01:03<00:00, 12.53s/it]\u001b[32m[I 2021-06-30 00:28:41,307]\u001b[0m Trial 67 finished with value: 0.6352 and parameters: {'min_child_samples': 10}. Best is trial 66 with value: 0.634675.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.633975: 100%|##########| 5/5 [01:03<00:00, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_error: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbmを実装して識別を行う--------------------------------------------------\n",
    "\n",
    "# ハイパーパラメータサーチ&モデル構築\n",
    "params = {'objective': 'multiclass',\n",
    "          'num_class': 9,\n",
    "          'metric': 'multi_error',\n",
    "          'random_seed': 0} \n",
    "\n",
    "# Optunaでのパラメータ探索\n",
    "gbm_o = lgb_o.train(params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    objective: multiclass\n",
      "    num_class: 9\n",
      "    metric: multi_error\n",
      "    random_seed: 0\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 0.0\n",
      "    lambda_l2: 0.0\n",
      "    num_leaves: 19\n",
      "    feature_fraction: 0.7\n",
      "    bagging_fraction: 1.0\n",
      "    bagging_freq: 0\n",
      "    min_child_samples: 20\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 100\n"
     ]
    }
   ],
   "source": [
    "# ベストパラメータの取得\n",
    "best_params = gbm_o.params\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.366025\n"
     ]
    }
   ],
   "source": [
    "# 調整後モデルで予測の実行\n",
    "Y_pred = gbm_o.predict(X_test, num_iteration = gbm_o.best_iteration)\n",
    "\n",
    "# 予測確率を整数へ\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# 識別率を求める\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f'score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  436,    1,    1,    0,  457,    0,  909,    9],\n",
       "       [   0, 2376,    6,    0,    1,  992,    2, 1368,   30],\n",
       "       [   0, 1127,    3,    1,    2,  698,    0, 1084,   20],\n",
       "       [   0,  226,    2,    0,    0,  257,    0,  459,    8],\n",
       "       [   0,  129,    0,    1,    0,  156,    0,  330,    8],\n",
       "       [   1,  857,    3,    0,    0, 5408,    0, 4105,   21],\n",
       "       [   1,  317,    1,    1,    0,  789,    0, 1842,   12],\n",
       "       [   1,  781,    8,    1,    0, 2750,    2, 6830,   43],\n",
       "       [   0, 1177,    6,    1,    1, 1384,    2, 2532,   24]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# 混同行列を表示\n",
    "cmx = confusion_matrix(y_test, y_pred)\n",
    "cmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  200000          0          0          0          0          0          0   \n",
       "1  200001          1          2          0          0          0          0   \n",
       "2  200002          0          1          7          1          0          0   \n",
       "3  200003          0          0          0          4          3          1   \n",
       "4  200004          0          0          5          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_65  feature_66  feature_67  \\\n",
       "0          0          0          0  ...           0           0           0   \n",
       "1          0          0          0  ...           3           1           3   \n",
       "2          0          0          6  ...           3           0           0   \n",
       "3          0          0          0  ...           0           0           0   \n",
       "4          0          0          0  ...           0           0           0   \n",
       "\n",
       "   feature_68  feature_69  feature_70  feature_71  feature_72  feature_73  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           3           0   \n",
       "2           0           0           3           0           2           0   \n",
       "3           1           0           0           0           4           0   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   feature_74  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csvファイルからPandas DataFrameへ読み込み\n",
    "submit_data = pd.read_csv('test.csv', delimiter=',', low_memory=False)\n",
    "\n",
    "# 冒頭を表示して確認\n",
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          1          2          0          0          0          0   \n",
       "2          0          1          7          1          0          0   \n",
       "3          0          0          0          4          3          1   \n",
       "4          0          0          5          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_65  feature_66  \\\n",
       "0          0          0          0          0  ...           0           0   \n",
       "1          0          0          0          0  ...           3           1   \n",
       "2          0          0          6          0  ...           3           0   \n",
       "3          0          0          0          0  ...           0           0   \n",
       "4          0          0          0          8  ...           0           0   \n",
       "\n",
       "   feature_67  feature_68  feature_69  feature_70  feature_71  feature_72  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           3           0           0           0           0           3   \n",
       "2           0           0           0           3           0           2   \n",
       "3           0           1           0           0           0           4   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   feature_73  feature_74  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           1           0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出データを適用できる形にする\n",
    "x_submit = submit_data.drop(['id'], axis=1)\n",
    "\n",
    "# 冒頭を表示して確認\n",
    "x_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出データを予測する\n",
    "predictions = gbm_o.predict(x_submit, num_iteration = gbm_o.best_iteration)\n",
    "\n",
    "# データの形を確認\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>0.047166</td>\n",
       "      <td>0.386004</td>\n",
       "      <td>0.163520</td>\n",
       "      <td>0.025399</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>0.173671</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.053809</td>\n",
       "      <td>0.112334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200001</th>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.084482</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.221131</td>\n",
       "      <td>0.080786</td>\n",
       "      <td>0.322586</td>\n",
       "      <td>0.125470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.033264</td>\n",
       "      <td>0.024879</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>0.672826</td>\n",
       "      <td>0.034104</td>\n",
       "      <td>0.128190</td>\n",
       "      <td>0.056798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200003</th>\n",
       "      <td>0.057256</td>\n",
       "      <td>0.082436</td>\n",
       "      <td>0.082390</td>\n",
       "      <td>0.048024</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>0.248217</td>\n",
       "      <td>0.062445</td>\n",
       "      <td>0.241977</td>\n",
       "      <td>0.162228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200004</th>\n",
       "      <td>0.037939</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.082335</td>\n",
       "      <td>0.028219</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>0.285166</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.235892</td>\n",
       "      <td>0.145374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
       "id                                                                             \n",
       "200000  0.047166  0.386004  0.163520  0.025399  0.013095  0.173671  0.025002   \n",
       "200001  0.044906  0.084482  0.087967  0.020954  0.011719  0.221131  0.080786   \n",
       "200002  0.028194  0.033264  0.024879  0.013417  0.008328  0.672826  0.034104   \n",
       "200003  0.057256  0.082436  0.082390  0.048024  0.015027  0.248217  0.062445   \n",
       "200004  0.037939  0.116377  0.082335  0.028219  0.014011  0.285166  0.054686   \n",
       "\n",
       "         Class_8   Class_9  \n",
       "id                          \n",
       "200000  0.053809  0.112334  \n",
       "200001  0.322586  0.125470  \n",
       "200002  0.128190  0.056798  \n",
       "200003  0.241977  0.162228  \n",
       "200004  0.235892  0.145374  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果を提出形式に変形\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "df_predictions.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "submit_data = pd.concat([submit_data.id,df_predictions],axis=1)\n",
    "submit_data = submit_data.set_index('id')\n",
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルとして出力\n",
    "submit_data.to_csv(\"submission_LGBM_optuna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
